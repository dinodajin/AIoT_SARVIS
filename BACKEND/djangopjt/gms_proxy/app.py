# -*- coding: utf-8 -*-
"""
í†µí•© EC2 ì„œë²„
- GMS Proxy (STT, LLM)
- Wake Word Validation
"""
import os, time, json, tempfile, re
from contextlib import asynccontextmanager
from fastapi import FastAPI, UploadFile, File, Header, HTTPException
from pydantic import BaseModel
import httpx

# â­ .env íŒŒì¼ ìë™ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()  # ê°™ì€ í´ë”ì˜ .env íŒŒì¼ì„ ì½ì–´ì„œ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •

# í™˜ê²½ ë³€ìˆ˜
JETSON_TOKEN = os.environ.get("JETSON_TOKEN", "")
GMS_KEY = os.environ.get("GMS_KEY", "")

# GMS API ì—”ë“œí¬ì¸íŠ¸
GMS_CHAT_URL = "https://gms.ssafy.io/gmsapi/api.openai.com/v1/chat/completions"
GMS_STT_URL = "https://gms.ssafy.io/gmsapi/api.openai.com/v1/audio/transcriptions"

# â­ ê¸€ë¡œë²Œ httpx í´ë¼ì´ì–¸íŠ¸ (ì»¤ë„¥ì…˜ í’€ë§)
http_client: httpx.AsyncClient = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì•± ì‹œì‘/ì¢…ë£Œ ì‹œ ì‹¤í–‰"""
    global http_client
    
    # ì•± ì‹œì‘ ì‹œ: httpx í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    limits = httpx.Limits(
        max_keepalive_connections=100,  # Keep-Alive ì»¤ë„¥ì…˜ ìµœëŒ€ 100ê°œ
        max_connections=200,             # ì „ì²´ ì»¤ë„¥ì…˜ ìµœëŒ€ 200ê°œ
        keepalive_expiry=None            # â­ Keep-Alive ë¬´ì œí•œ ìœ ì§€ (ì„œë²„ê°€ ëŠì„ ë•Œê¹Œì§€)
    )
    
    http_client = httpx.AsyncClient(
        limits=limits,
        timeout=httpx.Timeout(30.0, connect=5.0),  # ì—°ê²° 5ì´ˆ, ì „ì²´ 30ì´ˆ
        http2=False,  # HTTP/2 ë¹„í™œì„±í™” (h2 íŒ¨í‚¤ì§€ ë¶ˆí•„ìš”)
        follow_redirects=True
    )
    
    print("âœ… HTTP client initialized with connection pooling")
    
    yield
    
    # ì•± ì¢…ë£Œ ì‹œ: httpx í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬
    await http_client.aclose()
    print("âœ… HTTP client closed")

app = FastAPI(lifespan=lifespan)

def check_auth(x_token: str | None):
    if JETSON_TOKEN and x_token != JETSON_TOKEN:
        raise HTTPException(status_code=401, detail="unauthorized")

@app.get("/health")
def health():
    return {"ok": True, "services": ["gms_proxy", "wake_validation"]}


# =====================
# Wake Word Validation
# =====================

class VerifyWakeRequest(BaseModel):
    text: str
    target_words: list[str] = [
        "ì‹¸ë¹„ìŠ¤", "ì‚¬ë¹„ìŠ¤", "ì¨ë¹„ìŠ¤", "ì„œë¹„ìŠ¤", "ì„œë²„ìŠ¤",  # í•œê¸€
        "sabiss", "savis", "sarvis", "servus", "service"              # ì˜ë¬¸ (STTê°€ ì˜ë¬¸ìœ¼ë¡œ ì¸ì‹í•  ê²½ìš° ëŒ€ë¹„)
    ]


class VerifyWakeResponse(BaseModel):
    is_valid: bool
    confidence: float
    reason: str
    matched_word: str | None = None


def normalize_korean(text: str) -> str:
    """í•œê¸€/ì˜ë¬¸ í…ìŠ¤íŠ¸ ì •ê·œí™”"""
    text = text.lower().strip()
    
    # â­ ì˜ë¬¸ë„ í—ˆìš© (í•œê¸€ + ì˜ë¬¸ + ìˆ«ìë§Œ ë‚¨ê¹€)
    text = re.sub(r'[^ê°€-í£a-z0-9]', '', text)
    
    # ì—°ì† ê³µë°± ì œê±°
    text = re.sub(r'\s+', '', text)
    
    return text


def fuzzy_match(text: str, target: str, threshold: float = 0.7) -> float:
    """ê°„ë‹¨í•œ fuzzy matching (Levenshtein distance)"""
    text = normalize_korean(text)
    target = normalize_korean(target)
    
    if target in text:
        return 1.0
    
    # Levenshtein distance
    m, n = len(text), len(target)
    
    if m == 0:
        return 0.0
    if n == 0:
        return 0.0
    
    # DP table
    dp = [[0] * (n + 1) for _ in range(m + 1)]
    
    for i in range(m + 1):
        dp[i][0] = i
    for j in range(n + 1):
        dp[0][j] = j
    
    for i in range(1, m + 1):
        for j in range(1, n + 1):
            cost = 0 if text[i-1] == target[j-1] else 1
            dp[i][j] = min(
                dp[i-1][j] + 1,      # deletion
                dp[i][j-1] + 1,      # insertion
                dp[i-1][j-1] + cost  # substitution
            )
    
    distance = dp[m][n]
    max_len = max(m, n)
    
    similarity = 1.0 - (distance / max_len)
    return similarity


def verify_with_rules(text: str, target_words: list[str]) -> dict:
    """
    ê·œì¹™ ê¸°ë°˜ Wake word ê²€ì¦
    """
    text_norm = normalize_korean(text)
    
    # 1) Exact match
    for target in target_words:
        target_norm = normalize_korean(target)
        if target_norm == text_norm:
            return {
                "is_valid": True,
                "confidence": 1.0,
                "reason": f"exact_match: {target}",
                "matched_word": target,
            }
    
    # 2) Contains match
    for target in target_words:
        target_norm = normalize_korean(target)
        if target_norm in text_norm:
            return {
                "is_valid": True,
                "confidence": 0.95,
                "reason": f"contains: {target}",
                "matched_word": target,
            }
    
    # 3) Fuzzy match
    best_score = 0.0
    best_target = None
    
    for target in target_words:
        score = fuzzy_match(text, target)
        if score > best_score:
            best_score = score
            best_target = target
    
    # Threshold: 0.7
    if best_score >= 0.7:
        return {
            "is_valid": True,
            "confidence": best_score,
            "reason": f"fuzzy_match: {best_target}",
            "matched_word": best_target,
        }
    
    # 4) Negative cases
    # í™•ì‹¤íˆ ë‹¤ë¥¸ ë‹¨ì–´ë“¤
    negative_words = [
        "ì•ˆë…•", "í—¬ë¡œ", "í•˜ì´", "ì¢‹ì•„", "ì‹«ì–´", "ì˜ˆ", "ì•„ë‹ˆì˜¤",
        "ê³ ë§ˆì›Œ", "ë¯¸ì•ˆ", "ì˜ê°€", "ì•ˆë…•í•˜ì„¸ìš”", "ê°ì‚¬í•©ë‹ˆë‹¤",
    ]
    
    for neg in negative_words:
        if normalize_korean(neg) == text_norm:
            return {
                "is_valid": False,
                "confidence": 0.95,
                "reason": f"negative_word: {neg}",
                "matched_word": None,
            }
    
    # 5) Unknown
    return {
        "is_valid": False,
        "confidence": best_score if best_score > 0.3 else 0.1,
        "reason": f"no_match (best: {best_target}, score: {best_score:.2f})",
        "matched_word": None,
    }


@app.post("/verify_wake", response_model=VerifyWakeResponse)
async def verify_wake(req: VerifyWakeRequest):
    """
    Wake word ê²€ì¦ API
    
    Example:
        POST /verify_wake
        {
            "text": "ì‹¸ë¹„ìŠ¤ ì¼œì¤˜",
            "target_words": ["ì‹¸ë¹„ìŠ¤", "ì‚¬ë¹„ìŠ¤"]
        }
        
        Response:
        {
            "is_valid": true,
            "confidence": 0.95,
            "reason": "contains: ì‹¸ë¹„ìŠ¤",
            "matched_word": "ì‹¸ë¹„ìŠ¤"
        }
    """
    if not req.text:
        raise HTTPException(status_code=400, detail="text is required")
    
    result = verify_with_rules(req.text, req.target_words)
    
    return VerifyWakeResponse(**result)


# =====================
# GMS Proxy - STT
# =====================

@app.post("/stt")
async def stt(
    file: UploadFile = File(...), 
    language: str = "ko",
    x_token: str | None = Header(default=None)
):
    """
    Jetsonì˜ ìŒì„± íŒŒì¼ì„ GMS Whisper APIë¡œ ì „ì†¡
    """
    check_auth(x_token)
    
    if not GMS_KEY:
        raise HTTPException(status_code=500, detail="GMS_KEY not configured")
    
    t0 = time.time()
    
    try:
        # íŒŒì¼ ë°ì´í„° ì½ê¸°
        audio_data = await file.read()
        
        # â­ ê¸€ë¡œë²Œ http_client ì‚¬ìš© (ì»¤ë„¥ì…˜ ì¬ì‚¬ìš©)
        files = {
            "file": (file.filename or "audio.wav", audio_data, file.content_type or "audio/wav")
        }
        data = {
            "model": "whisper-1"
        }
        headers = {
            "Authorization": f"Bearer {GMS_KEY}"
        }
        
        response = await http_client.post(
            GMS_STT_URL,
            files=files,
            data=data,
            headers=headers
        )
        response.raise_for_status()
        result = response.json()
        
        # GMS ì‘ë‹µ í˜•ì‹: {"text": "..."}
        text = result.get("text", "").strip()
        
        return {
            "text": text,
            "timings": {"stt_ms": (time.time() - t0) * 1000.0}
        }
    
    except httpx.HTTPStatusError as e:
        raise HTTPException(status_code=e.response.status_code, detail=f"GMS STT failed: {e.response.text}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"STT error: {str(e)}")


# =====================
# GMS Proxy - LLM Parse
# =====================

class ParseReq(BaseModel):
    text: str
    state: dict = {}
    speaker_id: str | None = None
    request_id: str | None = None


# ëª…ë ¹ì–´ íŒŒì‹±ì„ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
COMMAND_SYSTEM_PROMPT = """ë„ˆëŠ” ìŒì„± ëª…ë ¹ì„ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” íŒŒì„œë‹¤.

## ì§€ì› ëª…ë ¹ì–´

### 1. ì´ë™
- "ì™¼ìª½ìœ¼ë¡œ ì´ë™", "ì¢ŒíšŒì „" â†’ {"cmd": "MOVE", "dir": "left"}
- "ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì´ë™", "ìš°íšŒì „" â†’ {"cmd": "MOVE", "dir": "right"}
- "ì•ìœ¼ë¡œ ê°€", "ì „ì§„" â†’ {"cmd": "MOVE", "dir": "forward"}
- "ë’¤ë¡œ ê°€", "í›„ì§„" â†’ {"cmd": "MOVE", "dir": "backward"}
- "ìœ„ë¡œ ì˜¬ë¼ê°€" â†’ {"cmd": "MOVE", "dir": "up"}
- "ì•„ë˜ë¡œ ë‚´ë ¤ê°€" â†’ {"cmd": "MOVE", "dir": "down"}

### 2. ì •ì§€
- "ë©ˆì¶°", "ì •ì§€", "ìŠ¤í†±" â†’ {"cmd": "STOP"}

### 3. ë”°ë¼ì˜¤ê¸°
- "ë”°ë¼ì™€", "ë”°ë¼ì˜¤ì„¸ìš”" â†’ {"cmd": "FOLLOW_ME"}

### 4. ì´ë¦¬ ì™€
- "ì´ë¦¬ ì™€", "ì´ìª½ìœ¼ë¡œ ì™€" â†’ {"cmd": "COME_HERE"}

### 5. ìœ íŠœë¸Œ (state.modeê°€ "youtube"ì¼ ë•Œë§Œ í—ˆìš©)
- "ìœ íŠœë¸Œ ì¼œì¤˜", "ìœ íŠœë¸Œ ì‹¤í–‰" â†’ {"cmd": "YOUTUBE_OPEN"}
- "ì¼ì‹œì •ì§€" â†’ {"cmd": "YOUTUBE_PAUSE"}
- "ì¬ìƒ" â†’ {"cmd": "YOUTUBE_PLAY"}
- "10ì´ˆ ì•ìœ¼ë¡œ" â†’ {"cmd": "YOUTUBE_SEEK", "sec": 10}
- "10ì´ˆ ë’¤ë¡œ" â†’ {"cmd": "YOUTUBE_SEEK", "sec": -10}

## ì‘ë‹µ í˜•ì‹

ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ê³ , ì„¤ëª…ì´ë‚˜ ì¶”ê°€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆë¼.

ì˜ˆì‹œ:
ì…ë ¥: "ì™¼ìª½ìœ¼ë¡œ ì´ë™í•´ì¤˜"
ì¶œë ¥: {"cmd": "MOVE", "dir": "left"}

ì…ë ¥: "ë©ˆì¶°"
ì¶œë ¥: {"cmd": "STOP"}

ì…ë ¥: "ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹"
ì¶œë ¥: {"cmd": "UNKNOWN"}
"""


@app.post("/llm_parse")
async def llm_parse(req: ParseReq, x_token: str | None = Header(default=None)):
    """
    ìì—°ì–´ ëª…ë ¹ì„ GMS GPT APIë¡œ íŒŒì‹±
    """
    check_auth(x_token)
    
    if not GMS_KEY:
        raise HTTPException(status_code=500, detail="GMS_KEY not configured")
    
    try:
        # ìƒíƒœ ì •ë³´ í¬í•¨
        mode = req.state.get("mode", "idle")
        context = f"í˜„ì¬ ëª¨ë“œ: {mode}"
        if mode != "youtube":
            context += "\n(ìœ íŠœë¸Œ ëª…ë ¹ì€ ìœ íŠœë¸Œ ëª¨ë“œì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥)"
        
        # â­ ê¸€ë¡œë²Œ http_client ì‚¬ìš© (ì»¤ë„¥ì…˜ ì¬ì‚¬ìš©)
        payload = {
            "model": "gpt-4o-mini",
            "messages": [
                {
                    "role": "system",
                    "content": COMMAND_SYSTEM_PROMPT
                },
                {
                    "role": "user",
                    "content": f"{context}\n\nëª…ë ¹: {req.text}"
                }
            ],
            "temperature": 0.1,
            "response_format": {"type": "json_object"}
        }
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {GMS_KEY}"
        }
        
        response = await http_client.post(
            GMS_CHAT_URL,
            json=payload,
            headers=headers
        )
        response.raise_for_status()
        result = response.json()
        
        # GPT ì‘ë‹µ íŒŒì‹±
        content = result["choices"][0]["message"]["content"]
        action = json.loads(content)
        
        # ìœ íŠœë¸Œ ëª…ë ¹ ê²€ì¦
        cmd = action.get("cmd", "")
        if cmd.startswith("YOUTUBE_") and mode != "youtube":
            return {
                "ok": False,
                "reason": "not_in_youtube"
            }
        
        # UNKNOWNì´ë©´ ì‹¤íŒ¨
        if cmd == "UNKNOWN":
            return {
                "ok": False,
                "reason": "unknown_command"
            }
        
        return {
            "ok": True,
            "action": action
        }
    
    except httpx.HTTPStatusError as e:
        raise HTTPException(status_code=e.response.status_code, detail=f"GMS Chat failed: {e.response.text}")
    except json.JSONDecodeError:
        return {
            "ok": False,
            "reason": "llm_parse_error"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"LLM parse error: {str(e)}")


# =====================
# Speaker Verification (ì„ íƒì‚¬í•­)
# =====================

#class VerifyReq(BaseModel):
#    embedding: list[float]
#    sr: int = 16000
#    seg_sec: float
#
#
#@app.post("/api/speaker/verify")
#def speaker_verify(req: VerifyReq, x_token: str | None = Header(default=None)):
#    """
#    í™”ì ê²€ì¦ - DB êµ¬í˜„ í•„ìš”
#    """
#    check_auth(x_token)
#    
#    # TODO: DBì—ì„œ í™”ì ê²€ì¦
#    # 1. req.embeddingê³¼ DBì˜ voice_vectors ë¹„êµ
#    # 2. cosine similarity ê³„ì‚°
#    # 3. threshold(0.35) ì´ìƒì´ë©´ ok=True
#    
#    return {
#        "ok": False,
#        "similarity": 0.0,
#        "speaker_id": None
#    }


if __name__ == "__main__":
    import uvicorn
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    if not GMS_KEY:
        print("âš ï¸  WARNING: GMS_KEY not set!")
        print("   export GMS_KEY='your_gms_api_key'")
    
    if not JETSON_TOKEN:
        print("âš ï¸  WARNING: JETSON_TOKEN not set!")
        print("   export JETSON_TOKEN='your_jetson_token'")
    
    print(f"ğŸš€ Starting unified server...")
    print(f"   Services:")
    print(f"   - STT: {GMS_STT_URL}")
    print(f"   - LLM: {GMS_CHAT_URL}")
    print(f"   - Wake Validation: /verify_wake")
    print(f"   - Health: /health")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)