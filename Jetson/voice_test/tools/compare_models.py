#!/usr/bin/env python3
"""
ECAPA-TDNN vs Wespeaker ResNet34 ì„±ëŠ¥ ë¹„êµ
4ê°œì˜ ìŒì„± íŒŒì¼ë¡œ í™”ì ì¸ì‹ ì •í™•ë„ í…ŒìŠ¤íŠ¸
"""

import numpy as np
import librosa
from scipy.spatial.distance import cosine
import sys

def extract_mel_spectrogram(audio_path, sr=16000):
    """
    Mel spectrogram ì¶”ì¶œ (ECAPA/Wespeaker ê³µí†µ)
    
    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        sr: ìƒ˜í”Œë§ ë ˆì´íŠ¸ (16kHz)
    
    Returns:
        mel_feats: (T, 80) shapeì˜ mel spectrogram
    """
    print(f"  Loading: {audio_path}")
    
    # ì˜¤ë””ì˜¤ ë¡œë“œ
    y, _ = librosa.load(audio_path, sr=sr)
    print(f"  Duration: {len(y)/sr:.2f}s")
    
    # Mel spectrogram ì¶”ì¶œ (80 bands)
    mel = librosa.feature.melspectrogram(
        y=y, 
        sr=sr,
        n_fft=512,
        hop_length=160,  # 10ms
        n_mels=80,
        fmin=20,
        fmax=7600
    )
    
    # Log scaleë¡œ ë³€í™˜
    mel = librosa.power_to_db(mel, ref=np.max)
    
    # (Freq, Time) -> (Time, Freq) ì „ì¹˜
    mel = mel.T.astype(np.float32)
    
    print(f"  Mel shape: {mel.shape}")
    
    return mel

def get_embedding(session, mel_feats):
    """
    ONNX ëª¨ë¸ë¡œ í™”ì ì„ë² ë”© ì¶”ì¶œ
    
    Args:
        session: ONNX Runtime session
        mel_feats: (T, 80) mel spectrogram
    
    Returns:
        embedding: Normalized embedding vector
    """
    # Batch dimension ì¶”ê°€: (T, 80) -> (1, T, 80)
    feats = np.expand_dims(mel_feats, axis=0)
    
    # ì¶”ë¡ 
    input_name = session.get_inputs()[0].name
    output_name = session.get_outputs()[0].name
    
    embedding = session.run([output_name], {input_name: feats})[0]
    
    # L2 Normalization
    embedding = embedding / np.linalg.norm(embedding)
    
    return embedding[0]

def cosine_similarity(emb1, emb2):
    """
    Cosine similarity ê³„ì‚°
    
    Returns:
        similarity: 0~1 ì‚¬ì´ ê°’ (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)
    """
    return 1 - cosine(emb1, emb2)

def compare_models(audio_files, ecapa_model_path, wespeaker_model_path):
    """
    ë‘ ëª¨ë¸ì˜ ì„±ëŠ¥ ë¹„êµ
    
    Args:
        audio_files: í…ŒìŠ¤íŠ¸í•  ìŒì„± íŒŒì¼ ë¦¬ìŠ¤íŠ¸
        ecapa_model_path: ECAPA ONNX ëª¨ë¸ ê²½ë¡œ
        wespeaker_model_path: Wespeaker ONNX ëª¨ë¸ ê²½ë¡œ
    """
    try:
        import onnxruntime as ort
    except ImportError:
        print("âŒ onnxruntimeì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("ì„¤ì¹˜: pip install onnxruntime --break-system-packages")
        return
    
    print("=" * 70)
    print("ğŸ¤ ECAPA-TDNN vs Wespeaker ResNet34 ì„±ëŠ¥ ë¹„êµ")
    print("=" * 70)
    
    # ========================================
    # 1. Mel Spectrogram ì¶”ì¶œ
    # ========================================
    print("\n[1ë‹¨ê³„] Mel Spectrogram ì¶”ì¶œ ì¤‘...")
    print("-" * 70)
    
    mel_features = []
    for i, audio_path in enumerate(audio_files):
        print(f"\níŒŒì¼ {i+1}/4:")
        mel = extract_mel_spectrogram(audio_path)
        mel_features.append(mel)
    
    # ========================================
    # 2. ECAPA-TDNN ì„ë² ë”© ì¶”ì¶œ
    # ========================================
    print("\n" + "=" * 70)
    print("[2ë‹¨ê³„] ECAPA-TDNN ì„ë² ë”© ì¶”ì¶œ...")
    print("-" * 70)
    
    try:
        ecapa_session = ort.InferenceSession(ecapa_model_path)
        print(f"âœ… ëª¨ë¸ ë¡œë“œ: {ecapa_model_path}")
        
        # ëª¨ë¸ ì •ë³´ ì¶œë ¥
        inp = ecapa_session.get_inputs()[0]
        out = ecapa_session.get_outputs()[0]
        print(f"   Input: {inp.name} {inp.shape}")
        print(f"   Output: {out.name} {out.shape}")
        
    except Exception as e:
        print(f"âŒ ECAPA ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    ecapa_embeddings = []
    for i, mel in enumerate(mel_features):
        print(f"\níŒŒì¼ {i+1}: ì„ë² ë”© ì¶”ì¶œ ì¤‘...")
        emb = get_embedding(ecapa_session, mel)
        ecapa_embeddings.append(emb)
        print(f"  ì„ë² ë”© shape: {emb.shape}")
        print(f"  ì„ë² ë”© norm: {np.linalg.norm(emb):.4f}")
    
    # ========================================
    # 3. Wespeaker ResNet34 ì„ë² ë”© ì¶”ì¶œ
    # ========================================
    print("\n" + "=" * 70)
    print("[3ë‹¨ê³„] Wespeaker ResNet34 ì„ë² ë”© ì¶”ì¶œ...")
    print("-" * 70)
    
    try:
        wespeaker_session = ort.InferenceSession(wespeaker_model_path)
        print(f"âœ… ëª¨ë¸ ë¡œë“œ: {wespeaker_model_path}")
        
        # ëª¨ë¸ ì •ë³´ ì¶œë ¥
        inp = wespeaker_session.get_inputs()[0]
        out = wespeaker_session.get_outputs()[0]
        print(f"   Input: {inp.name} {inp.shape}")
        print(f"   Output: {out.name} {out.shape}")
        
    except Exception as e:
        print(f"âŒ Wespeaker ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    wespeaker_embeddings = []
    for i, mel in enumerate(mel_features):
        print(f"\níŒŒì¼ {i+1}: ì„ë² ë”© ì¶”ì¶œ ì¤‘...")
        emb = get_embedding(wespeaker_session, mel)
        wespeaker_embeddings.append(emb)
        print(f"  ì„ë² ë”© shape: {emb.shape}")
        print(f"  ì„ë² ë”© norm: {np.linalg.norm(emb):.4f}")
    
    # ========================================
    # 4. ìœ ì‚¬ë„ ë¹„êµ (ëª¨ë“  ìŒ)
    # ========================================
    print("\n" + "=" * 70)
    print("[4ë‹¨ê³„] ìœ ì‚¬ë„ ë¹„êµ - ëª¨ë“  íŒŒì¼ ìŒ")
    print("=" * 70)
    
    threshold = 0.80
    print(f"\nğŸ¯ íŒì • ê¸°ì¤€: similarity >= {threshold} â†’ ê°™ì€ í™”ì")
    print("-" * 70)
    
    ecapa_wins = 0
    wespeaker_wins = 0
    total_pairs = 0
    
    for i in range(len(audio_files)):
        for j in range(i+1, len(audio_files)):
            total_pairs += 1
            
            # ECAPA ìœ ì‚¬ë„
            ecapa_sim = cosine_similarity(
                ecapa_embeddings[i], 
                ecapa_embeddings[j]
            )
            
            # Wespeaker ìœ ì‚¬ë„
            wespeaker_sim = cosine_similarity(
                wespeaker_embeddings[i], 
                wespeaker_embeddings[j]
            )
            
            # ì°¨ì´
            diff = wespeaker_sim - ecapa_sim
            
            print(f"\nğŸ“Š íŒŒì¼ {i+1} vs íŒŒì¼ {j+1}:")
            print(f"   ECAPA:     {ecapa_sim:.4f} {'âœ… PASS' if ecapa_sim >= threshold else 'âŒ FAIL'}")
            print(f"   Wespeaker: {wespeaker_sim:.4f} {'âœ… PASS' if wespeaker_sim >= threshold else 'âŒ FAIL'}")
            print(f"   ì°¨ì´:      {diff:+.4f}", end="")
            
            if abs(diff) < 0.01:
                print(" (ê±°ì˜ ë™ì¼)")
            elif diff > 0:
                print(" â†’ ğŸ† Wespeaker ìŠ¹")
                wespeaker_wins += 1
            else:
                print(" â†’ ğŸ† ECAPA ìŠ¹")
                ecapa_wins += 1
    
    # ========================================
    # 5. ìµœì¢… ê²°ê³¼
    # ========================================
    print("\n" + "=" * 70)
    print("ğŸ“ˆ ìµœì¢… ê²°ê³¼")
    print("=" * 70)
    
    print(f"\nì´ ë¹„êµ ìŒ: {total_pairs}")
    print(f"ECAPA ìŠ¹ë¦¬:     {ecapa_wins}íšŒ")
    print(f"Wespeaker ìŠ¹ë¦¬: {wespeaker_wins}íšŒ")
    print(f"ë¬´ìŠ¹ë¶€:         {total_pairs - ecapa_wins - wespeaker_wins}íšŒ")
    
    print("\n" + "=" * 70)
    if wespeaker_wins > ecapa_wins:
        print("ğŸ‰ ê²°ë¡ : Wespeaker ResNet34ê°€ ë” ìš°ìˆ˜!")
        print("   â†’ ëª¨ë¸ êµì²´ ê¶Œì¥ âœ…")
    elif ecapa_wins > wespeaker_wins:
        print("âš ï¸  ê²°ë¡ : ECAPA-TDNNì´ ë” ìš°ìˆ˜")
        print("   â†’ í˜„ì¬ ëª¨ë¸ ìœ ì§€ ê¶Œì¥")
    else:
        print("ğŸ¤” ê²°ë¡ : ë‘ ëª¨ë¸ ì„±ëŠ¥ ë¹„ìŠ·")
        print("   â†’ ì¶”ê°€ í…ŒìŠ¤íŠ¸ í•„ìš”")
    print("=" * 70)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    # í…ŒìŠ¤íŠ¸í•  ìŒì„± íŒŒì¼ë“¤ (tools/ ë””ë ‰í† ë¦¬ ê¸°ì¤€)
    audio_files = [
        "sample/voice_1.wav.pcm16k.wav",
        "sample/voice_2.wav.pcm16k.wav",
        "sample/voice_3.wav.pcm16k.wav",
        "sample/voice_4.wav.pcm16k.wav",
    ]
    
    # ëª¨ë¸ ê²½ë¡œ (tools/ ë””ë ‰í† ë¦¬ ê¸°ì¤€)
    ecapa_model = "../models/speaker/ecapa.onnx"
    wespeaker_model = "wespeaker_resnet34_korean.onnx"
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    import os
    for audio_file in audio_files:
        if not os.path.exists(audio_file):
            print(f"âŒ íŒŒì¼ ì—†ìŒ: {audio_file}")
            return
    
    if not os.path.exists(ecapa_model):
        print(f"âŒ ECAPA ëª¨ë¸ ì—†ìŒ: {ecapa_model}")
        print("ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ ê²½ë¡œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.")
        return
    
    if not os.path.exists(wespeaker_model):
        print(f"âŒ Wespeaker ëª¨ë¸ ì—†ìŒ: {wespeaker_model}")
        print("convert_wespeaker_to_onnx.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    # ë¹„êµ ì‹¤í–‰
    compare_models(audio_files, ecapa_model, wespeaker_model)

if __name__ == "__main__":
    main()