from __future__ import annotations

import collections
import json
import queue
import threading
import time
import requests  # HTTP í†µì‹ ìš©
from dataclasses import dataclass
from pathlib import Path
from typing import Optional

import numpy as np
import alsaaudio
import webrtcvad

import config as C
from pipeline.router import VoiceCommandPipeline

# ========================
# RMS_METER Check Helper
# ========================
import math


def rms_i16(x_i16: np.ndarray) -> float:
    # x_i16: int16 mono
    if x_i16.size == 0:
        return 0.0
    xf = x_i16.astype(np.float32)
    return float(np.sqrt(np.mean(xf * xf) + 1e-12))


def dbfs_from_rms_i16(rms: float) -> float:
    # int16 full-scale = 32768
    return 20.0 * math.log10((rms / 32768.0) + 1e-12)


def level_bar(dbfs: float, width: int = 30) -> str:
    # -60dBFS ~ 0dBFS ë¥¼ 0~widthë¡œ ë§¤í•‘
    db = max(-60.0, min(0.0, dbfs))
    n = int(round((db + 60.0) / 60.0 * width))
    return "â–ˆ" * n + " " * (width - n)


# =========================
# Shared state / Config
# =========================
STATE_DIR = Path("/run/sarvis")
CURRENT_USER_PATH = STATE_DIR / "current_user.json"
ENROLL_FLAG = STATE_DIR / "enrolling.flag"

# Jetson ë¡œì»¬ Flask ì„œë²„ (app_image_embedding.pyì˜ /manual_control ì—”ë“œí¬ì¸íŠ¸)
JETSON_CONTROL_URL = "http://127.0.0.1:5000/button_command"
JETSON_VOICE_URL = "http://127.0.0.1:5000/voice_command"  # ì¶”ì  ëª…ë ¹ìš©


@dataclass
class Segment:
    idx: int
    sr: int
    audio_i16: np.ndarray


def int16_from_bytes(b: bytes) -> np.ndarray:
    return np.frombuffer(b, dtype=np.int16)


def safe_load_current_login_id() -> Optional[str]:
    try:
        if not CURRENT_USER_PATH.exists():
            return None
        txt = CURRENT_USER_PATH.read_text(encoding="utf-8")
        obj = json.loads(txt)
        # uid í˜¹ì€ login_id ì¤‘ ì¡´ì¬í•˜ëŠ” ê²ƒì„ ì‚¬ìš©
        login_id = (obj.get("uid") or obj.get("login_id") or "").strip()
        return login_id if login_id else None
    except Exception:
        return None


# =========================
# Threads
# =========================
class LoginGate(threading.Thread):
    # ë¡œê·¸ì¸ ìƒíƒœë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ì²´í¬í•˜ì—¬ ë…¹ìŒ ë° íŒŒì´í”„ë¼ì¸ í™œì„±/ë¹„í™œì„± ê²°ì •
    def __init__(self, enabled_event: threading.Event, stop_evt: threading.Event, poll_sec: float = 0.2):
        super().__init__(daemon=True)
        self.enabled_event = enabled_event
        self.stop_evt = stop_evt
        self.poll_sec = poll_sec
        self.current_id: Optional[str] = None

    def run(self):
        while not self.stop_evt.is_set():
            # ë“±ë¡ ì¤‘ì¼ ë•ŒëŠ” ë©”ì¸ íŒŒì´í”„ë¼ì¸ ì¤‘ì§€
            if ENROLL_FLAG.exists():
                if self.enabled_event.is_set():
                    print("[GATE] Enrollment in progress. Pausing main pipeline.", flush=True)
                    self.enabled_event.clear()
            else:
                login_id = safe_load_current_login_id()
                if login_id:
                    if not self.enabled_event.is_set() or self.current_id != login_id:
                        print(f"[GATE] User '{login_id}' logged in. Pipeline ENABLED.", flush=True)
                        self.current_id = login_id
                        self.enabled_event.set()
                else:
                    if self.enabled_event.is_set():
                        print("[GATE] No user logged in. Pipeline DISABLED.", flush=True)
                        self.current_id = None
                        self.enabled_event.clear()

            time.sleep(self.poll_sec)


class VADProducer(threading.Thread):
    # ALSA ë§ˆì´í¬ì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ VAD í›„ ìœ íš¨í•œ ìŒì„± ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±
    def __init__(self, out_q: queue.Queue[Segment], stop_evt: threading.Event, enabled_event: threading.Event):
        super().__init__(daemon=True)
        self.out_q = out_q
        self.stop_evt = stop_evt
        self.enabled_event = enabled_event

        self.vad = webrtcvad.Vad(int(getattr(C, "VAD_MODE", 3)))

        # VAD ì„¤ì • (48kHzëŠ” ë°˜ë“œì‹œ 10ms, 20ms, 30ms í”„ë ˆì„ë§Œ ì§€ì›)
        self.frame_ms = 20  # 48kHzì—ì„œ ì•ˆì •ì ì¸ í”„ë ˆì„ í¬ê¸°
        self.frame_size = int(C.SR * self.frame_ms / 1000)
        self.ring_buffer = collections.deque(maxlen=int(C.PRE_ROLL_SEC * 1000 / self.frame_ms))
        self.triggered = False
        self.voiced_frames = []
        self.silence_count = 0
        self.silence_limit = int(C.SILENCE_TIMEOUT * 1000 / self.frame_ms)
        self.max_frames = int(10.0 * 1000 / self.frame_ms)  # â­ ìµœëŒ€ 10ì´ˆ ë…¹ìŒ
        self.seg_idx = 0

        # RMS meter / gate
        self._show_level = bool(getattr(C, "SHOW_LEVEL", False))
        self._rms_gate = float(getattr(C, "RMS_GATE", 0.0))
        self._lvl_last_t = 0.0
        # systemd/journal í™˜ê²½ì´ë©´ ë„ˆë¬´ ìì£¼ ì°ìœ¼ë©´ ë¡œê·¸ê°€ í­ì£¼í•˜ë‹ˆ 0.5ì´ˆ ê¶Œì¥
        self._lvl_period_sec = 0.5
        self._rms_ema = 0.0
        self._ema_alpha = 0.25  # 0~1 (í´ìˆ˜ë¡ ë°˜ì‘ ë¹ ë¦„)

    def run(self):
        try:
            # ALSA ì„¤ì •
            mic = alsaaudio.PCM(
                alsaaudio.PCM_CAPTURE,
                alsaaudio.PCM_NORMAL,
                device=getattr(C, "DEVICE_NAME", "default"),
            )
            mic.setchannels(1)
            mic.setrate(C.SR)
            mic.setformat(alsaaudio.PCM_FORMAT_S16_LE)
            mic.setperiodsize(self.frame_size)

            # ë§ˆì´í¬ ì •ë³´ ì¶œë ¥
            print(f"[PRODUCER] Microphone device: {getattr(C, 'DEVICE_NAME', 'default')}", flush=True)
            print(f"[PRODUCER] Sample rate: {C.SR}, Frame size: {self.frame_size}", flush=True)
        except Exception as e:
            print(f"[PRODUCER] ALSA Open Error: {e}", flush=True)
            return

        print("[PRODUCER] Recording started.", flush=True)

        # ìŒì„± ê°ì§€ ì¹´ìš´í„° (ë””ë²„ê¹…ìš©)
        frame_count = 0
        speech_frame_count = 0

        while not self.stop_evt.is_set():
            if not self.enabled_event.is_set():
                time.sleep(0.1)
                continue

            l, data = mic.read()
            if l <= 0:
                continue

            # VADëŠ” ì •í™•íˆ frame_size ë°”ì´íŠ¸ë¥¼ ìš”êµ¬
            if len(data) != self.frame_size * 2:  # 2 bytes per sample (int16)
                continue

            # â­ ì‹¤ì‹œê°„ ë…¸ì´ì¦ˆ ì œê±° (noisereduce)
            audio_i16 = int16_from_bytes(data)
            audio_f32 = audio_i16.astype(np.float32) / 32768.0

            # noisereduce ì ìš© (stationary noise reduction)
            try:
                import noisereduce as nr

                audio_f32_clean = nr.reduce_noise(
                    y=audio_f32,
                    sr=C.SR,
                    stationary=True,
                    prop_decrease=0.8,  # ë…¸ì´ì¦ˆ ì œê±° ê°•ë„ (0.0~1.0)
                )
            except ImportError:
                audio_f32_clean = audio_f32
            except Exception:
                audio_f32_clean = audio_f32

            # ë‹¤ì‹œ int16ë¡œ ë³€í™˜
            audio_i16_clean = (audio_f32_clean * 32768.0).astype(np.int16)
            data_clean = audio_i16_clean.tobytes()

            # ===== RMS ê³„ì‚° (gate ë˜ëŠ” meterìš©) =====
            need_rms = (self._rms_gate > 0.0) or self._show_level
            if need_rms:
                r = rms_i16(audio_i16_clean)
                self._rms_ema = (1.0 - self._ema_alpha) * self._rms_ema + self._ema_alpha * r
                db = dbfs_from_rms_i16(self._rms_ema)

                # ===== RMS ì¶œë ¥ (ì›í•  ë•Œë§Œ) =====
                if self._show_level:
                    now_t = time.time()
                    if (now_t - self._lvl_last_t) >= self._lvl_period_sec:
                        gate_on = (self._rms_gate > 0.0 and self._rms_ema >= self._rms_gate)
                        bar = level_bar(db, width=30)
                        print(
                            f"[RMS] {self._rms_ema:7.1f}  {db:6.1f} dBFS |{bar}| gate={self._rms_gate:.0f} {'ON ' if gate_on else 'off'}",
                            flush=True,
                        )
                        self._lvl_last_t = now_t

            try:
                # ë…¸ì´ì¦ˆ ì œê±°ëœ ë°ì´í„°ë¡œ VAD
                is_speech = self.vad.is_speech(data_clean, C.SR)

                # RMS gate ì ìš©: gate ë¯¸ë§Œì´ë©´ speech ë¡œ ì¸ì •í•˜ì§€ ì•ŠìŒ
                if self._rms_gate > 0.0 and self._rms_ema < self._rms_gate:
                    is_speech = False
            except Exception:
                # VAD ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
                continue

            # ë””ë²„ê¹…: ì£¼ê¸°ì ìœ¼ë¡œ ìƒíƒœ ì¶œë ¥ (5ì´ˆë§ˆë‹¤)
            frame_count += 1
            if is_speech:
                speech_frame_count += 1

            if frame_count % 250 == 0:  # ì•½ 5ì´ˆë§ˆë‹¤ (20ms * 250 = 5000ms)
                print(
                    f"[PRODUCER] Frames: {frame_count}, Speech: {speech_frame_count} ({speech_frame_count*100//frame_count}%)",
                    flush=True,
                )
                speech_frame_count = 0
                frame_count = 0

            if not self.triggered:
                self.ring_buffer.append((data_clean, is_speech))  # â­ ë…¸ì´ì¦ˆ ì œê±°ëœ ë°ì´í„° ì €ì¥
                num_voiced = len([f for f, speech in self.ring_buffer if speech])
                if num_voiced > 0.8 * self.ring_buffer.maxlen:
                    self.triggered = True
                    print("ğŸ¤ [PRODUCER] Speech detected! Starting recording...", flush=True)
                    for f, s in self.ring_buffer:
                        self.voiced_frames.append(f)
                    self.ring_buffer.clear()
            else:
                self.voiced_frames.append(data_clean)  # â­ ë…¸ì´ì¦ˆ ì œê±°ëœ ë°ì´í„° ì €ì¥
                if not is_speech:
                    self.silence_count += 1
                else:
                    self.silence_count = 0

                # â­ ìµœëŒ€ ê¸¸ì´ ë„ë‹¬ ì‹œ ê°•ì œ ì¢…ë£Œ
                if len(self.voiced_frames) >= self.max_frames:
                    print("âš ï¸  [PRODUCER] Max length reached, forcing segment end", flush=True)
                    self.silence_count = self.silence_limit + 1

                if self.silence_count > self.silence_limit:
                    # ìŒì„± êµ¬ê°„ ì¢…ë£Œ (ì¹¨ë¬µ or ìµœëŒ€ ê¸¸ì´)
                    full_audio = b"".join(self.voiced_frames)
                    audio_i16_seg = int16_from_bytes(full_audio)

                    # ìµœì†Œ ê¸¸ì´ ì²´í¬
                    if len(audio_i16_seg) > int(C.MIN_SEG_SEC * C.SR):
                        self.seg_idx += 1
                        duration = len(audio_i16_seg) / C.SR
                        print(f"âœ… [PRODUCER] Segment #{self.seg_idx} recorded ({duration:.2f}s)", flush=True)
                        try:
                            self.out_q.put(Segment(self.seg_idx, C.SR, audio_i16_seg), timeout=0.1)
                        except queue.Full:
                            print("âš ï¸  [PRODUCER] Queue full, segment dropped", flush=True)
                    else:
                        print("âš ï¸  [PRODUCER] Segment too short, ignored", flush=True)

                    self.triggered = False
                    self.voiced_frames = []
                    self.silence_count = 0


class PipelineWorker(threading.Thread):
    # ìŒì„± ì„¸ê·¸ë¨¼íŠ¸ë¥¼ íŒŒì´í”„ë¼ì¸ì— ì „ë‹¬í•˜ê³  ê²°ê³¼ë¥¼ ì²˜ë¦¬(RPI ì „ì†¡)
    def __init__(self, in_q: queue.Queue[Segment], stop_evt: threading.Event, enabled_event: threading.Event, gate: LoginGate):
        super().__init__(daemon=True)
        self.in_q = in_q
        self.stop_evt = stop_evt
        self.enabled_event = enabled_event
        self.gate = gate
        self.pipe: Optional[VoiceCommandPipeline] = None

    def _ensure_pipe(self, login_id: str):
        if self.pipe is None:
            print(f"[WORKER] Initializing pipeline for user: {login_id}", flush=True)
            self.pipe = VoiceCommandPipeline()

    def _close_pipe(self):
        self.pipe = None

    def _send_to_rpi(self, result: dict):
        # ì¸ì‹ëœ ëª…ë ¹ì–´ë¥¼ ì ì ˆí•œ ê³³ìœ¼ë¡œ ì „ì†¡
        # - ë¡œë´‡íŒ” ì œì–´: Jetson Flask â†’ ë¼ì¦ˆë² ë¦¬íŒŒì´
        # - ìœ íŠœë¸Œ/ì•± ì œì–´: ë°±ì—”ë“œ ì„œë²„ â†’ ì•±
        cmd = result.get("command")
        if not cmd or cmd in ("REJECT", "UNKNOWN"):
            return

        # í˜„ì¬ ë¡œê·¸ì¸ëœ ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        uid = None
        try:
            if CURRENT_USER_PATH.exists():
                with open(CURRENT_USER_PATH, "r") as f:
                    user_data = json.load(f)
                    uid = user_data.get("uid")
        except Exception as e:
            print(f"âš ï¸  [CMD] Failed to load user: {e}", flush=True)
            return

        if not uid:
            print("âš ï¸  [CMD] No user logged in, cannot send command", flush=True)
            return

        # ìœ íŠœë¸Œ ëª…ë ¹ì€ ë°±ì—”ë“œ ì„œë²„ë¡œ ì „ì†¡
        if cmd.startswith("YOUTUBE_"):
            self._send_to_backend_server(cmd, result, uid)
            return

        # ì¶”ì  ëª…ë ¹ (FOLLOW_ME, STOP, COME_HERE, HOME)
        if cmd in ("FOLLOW_ME", "STOP", "COME_HERE", "HOME"):
            self._send_voice_command(cmd, uid)
            return

        # ë¡œë´‡íŒ” ëª…ë ¹ì€ ë¼ì¦ˆë² ë¦¬íŒŒì´ë¡œ ì „ì†¡
        command_str = self._convert_voice_to_rpi_command(cmd, result)

        if not command_str:
            print(f"âš ï¸  [CMD] Cannot convert command: {cmd}", flush=True)
            return

        # Jetson ë¡œì»¬ Flask ì„œë²„ì˜ /button_command ì—”ë“œí¬ì¸íŠ¸ë¡œ ì „ì†¡ (6ë²ˆ ë°˜ë³µ)
        payload = {"command": command_str}

        try:
            success_count = 0
            for i in range(6):
                resp = requests.post(JETSON_CONTROL_URL, json=payload, timeout=1.0)
                if resp.status_code == 200:
                    success_count += 1
                time.sleep(0.05)  # 50ms ê°„ê²©
    
            if success_count == 6:
                print(f"âœ… [CMDâ†’RPI] {command_str} x6", flush=True)
            else:
                print(f"âš ï¸  [CMDâ†’RPI] {command_str} partial success: {success_count}/6", flush=True)
        except Exception as e:
            print(f"âŒ [CMDâ†’RPI] Error: {e}", flush=True)

    def _send_voice_command(self, cmd: str, uid: str):
        """ì¶”ì  ëª…ë ¹ ì „ì†¡ (FOLLOW_ME, STOP, COME_HERE, HOME)"""
        # ëª…ë ¹ ë§¤í•‘
        command_map = {
            "FOLLOW_ME": "TRACK_ON",
            "STOP": "TRACK_OFF",
            "COME_HERE": "COME_HERE",
            "HOME": "HOME"
        }
        
        command_str = command_map.get(cmd)
        if not command_str:
            print(f"âš ï¸  [VOICE] Unknown voice command: {cmd}", flush=True)
            return
        
        payload = {"command": command_str}
        
        try:
            resp = requests.post(JETSON_VOICE_URL, json=payload, timeout=1.0)
            if resp.status_code == 200:
                print(f"âœ… [CMDâ†’VOICE] {command_str}", flush=True)
            else:
                print(f"âŒ [CMDâ†’VOICE] Failed: status={resp.status_code}", flush=True)
        except Exception as e:
            print(f"âŒ [CMDâ†’VOICE] Error: {e}", flush=True)

    def _send_to_backend_server(self, cmd: str, result: dict, uid: str):
        # ìœ íŠœë¸Œ/ì•± ì œì–´ ëª…ë ¹ì„ ë°±ì—”ë“œ ì„œë²„ë¡œ ì „ì†¡
        backend_url = getattr(C, "SERVER_BASE", "http://i14a104.p.ssafy.io:8080")
        endpoint = f"{backend_url}/api/control/voice/"

        # ëª¨ë“  ëª…ë ¹ì–´ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ì „ë‹¬
        payload = {"uid": uid, "command": cmd}

        try:
            resp = requests.post(endpoint, json=payload, timeout=2.0)
            if resp.status_code == 200:
                print(f"âœ… [CMDâ†’SERVER] {cmd} (to app)", flush=True)
            else:
                print(f"âŒ [CMDâ†’SERVER] Failed: status={resp.status_code}", flush=True)
        except Exception as e:
            print(f"âŒ [CMDâ†’SERVER] Error: {e}", flush=True)

    def _convert_voice_to_rpi_command(self, cmd: str, result: dict) -> Optional[str]:
        # ìŒì„± ëª…ë ¹ì„ ë¼ì¦ˆë² ë¦¬íŒŒì´ ë¡œë´‡íŒ” ì´ë™ ëª…ë ¹ìœ¼ë¡œ ë³€í™˜ (MOVEë§Œ)
        if cmd == "MOVE":
            direction = result.get("dir")
            if direction == "left":
                return "LEFT"
            if direction == "right":
                return "RIGHT"
            if direction == "up":
                return "UP"
            if direction == "down":
                return "DOWN"
            if direction == "forward":
                return "FAR"
            if direction == "backward":
                return "NEAR"

        return None

    def run(self):
        while not self.stop_evt.is_set():
            login_id = self.gate.current_id
            if not login_id:
                # í ë¹„ìš°ê¸°
                while not self.in_q.empty():
                    self.in_q.get()
                self._close_pipe()
                self.enabled_event.wait(timeout=0.2)
                continue

            self._ensure_pipe(login_id)

            try:
                seg = self.in_q.get(timeout=0.1)
            except queue.Empty:
                if self.pipe:
                    tick_result = self.pipe.tick_time()
                    if tick_result:
                        self._send_to_rpi(tick_result)
                continue

            if self.pipe:
                result = self.pipe.handle_segment(seg.idx, seg.sr, seg.audio_i16)

                if result:
                    self._send_to_rpi(result)

                tick_result = self.pipe.tick_time()
                if tick_result:
                    self._send_to_rpi(tick_result)

        self._close_pipe()


def main():
    print("=" * 50)
    print("SARVIS Voice Control System Active")
    print("=" * 50)

    seg_q = queue.Queue(maxsize=5)
    stop_evt = threading.Event()
    enabled_event = threading.Event()

    gate = LoginGate(enabled_event, stop_evt)
    prod = VADProducer(seg_q, stop_evt, enabled_event)
    work = PipelineWorker(seg_q, stop_evt, enabled_event, gate)

    gate.start()
    prod.start()
    work.start()

    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        print("\n[MAIN] Stopping...")
        stop_evt.set()
        gate.join()
        prod.join()
        work.join()
        print("[MAIN] All threads stopped. Bye.")


if __name__ == "__main__":
    main()