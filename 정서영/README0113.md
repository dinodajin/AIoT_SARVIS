## 2026.01.13. 기획 내용

**시각장애인을 위한 스마트 안경 + 골전도 이어폰**

- 안경에 달린 카메라를 통해 AI 가 상황 인식 → 텍스트화 → 이어폰으로 상황 전달
- 이어폰 버튼을 누르면 음성 인식 기능 → 상황에 맞는 답변 제공

### 'AI 페이스 메모리' (Social Assistance)

시각장애인이 가장 어려워하는 것 중 하나가 "내 앞에 서 있는 사람이 누구인가?"입니다.

- **아이디어:** 자주 만나는 지인(가족, 친구)의 얼굴을 미리 등록해두면, 카메라가 얼굴을 인식해 이어폰으로 "앞에 친구 '민수'가 있습니다"라고 속삭여줍니다.
- **시연 포인트:** 시연 현장에서 등록된 인물이 나타나면 AI가 즉시 이름을 부르는 모습을 보여주면 임팩트가 매우 큽니다.

### '긴급 상황 자동 감지' (Safety Guard)

- **아이디어:** AI가 넘어짐이나 비명, 혹은 빠르게 다가오는 차량을 감지하면 즉시 등록된 보호자에게 현재 위치와 카메라 영상을 전송합니다.
- **시연 포인트:** 시연자가 갑자기 쓰러지는 시늉을 하면, 시스템이 "위험이 감지되었습니다. 보호자에게 알림을 보냅니다"라고 말하며 관리자 페이지에 긴급 알람이 뜨는 것을 보여줍니다.
- **기술적 구현:** 가속도 센서 데이터 또는 비전 기반의 포즈 추정(Pose Estimation).

### 1. 하드웨어 시스템 구성 (Hardware Architecture)

- **안경부 (Input):** 소형 초광각 카메라 모듈(안경 다리 부착) + 가속도/자이로 센서(넘어짐 감지용).
- **허리 제어기 (Processing):** 라즈베리 파이 5(또는 Jetson Nano) + 대용량 보조배터리. 안경과 유선/무선으로 연결되어 AI 연산(얼굴 인식, 상황 분석)을 수행합니다.
- **이어폰부 (Output/Interface):** **무선 골전도 이어폰**. 귀를 막지 않아 주변 소리를 들을 수 있으며, 내장된 버튼으로 음성 인식(STT)을 트리거합니다.

---

### 2. 핵심 기능 상세 구현 (Core Logic)

### ① AI 페이스 메모리 (지인 인식)

- **동작:** 카메라가 사람을 포착하면 얼굴 특징점(Embedding)을 추출합니다. 미리 등록된 지인 데이터베이스와 비교하여 일치하면 이름을 출력합니다.
- **차별점:** 단순 인식이 아니라 "3미터 앞에 민수님이 있습니다"와 같이 **거리 정보**를 함께 제공합니다.

### ② 긴급 상황 자동 감지 (Safety Guard)

- **넘어짐 감지:** 가속도 센서의 급격한 변화와 비전 기반의 'Pose Estimation(사람이 지면과 수평인지)'을 교차 검증하여 오작동을 줄입니다.
- **차량 접근:** 영상 내 객체 크기가 급격히 커지는 사물(차량)을 탐지하여 "위험, 뒤로 물러나세요"라고 즉시 경고합니다.

대상: 생활에 어려움을 겪는 시각장애인

목적: 카메라를 통한 상황 인식 및 AI 판단, 음성을 통한 안내

→ 가능한 작은 카메라를 안경 옆에 붙임

→ 영상정보를 허리춤에 달린 기기에 전송하여 AI를 통한 상황 판단 및 음성신호 출력 

→ 골전도 이어폰(줄? 무선?)으로 출력. 

→ 이어폰 버튼을 누르면 음성 인식 가능, AI가 상황에 맞는 답변 제공 

발생 가능한 문제점

> "카메라가 많아지면 연산량이 늘어나 반응 속도(Latency)가 느려질 텐데, 위험 상황에서 즉각 대응이 가능할까요?"
> 
- **방어 전략:** * **관심 영역(ROI) 설정:** 전체 360도를 고화질로 분석하는 대신, 전방은 고해상도(사물/글자 인식), 후방과 측방은 저해상도(동체 감지 위주)로 차등 처리하여 연산 속도 높인다
    - **데이터 경량화:** YOLO-tiny나 MobileNet 같은 경량화 모델을 최적화(TensorRT 등)하여 실시간성(30fps 이상)을 확보

> "360도 카메라로 주변 사람들의 얼굴을 허락 없이 계속 촬영하고 인식하는 건 개인정보 침해 아닌가요?"
> 
- **방어 전략:** * **On-Device AI:** 영상을 서버로 전송하지 않고 기기 자체에서 즉시 처리 후 삭제합니다.
    - **얼굴 특징점 저장:** 얼굴 이미지를 저장하는 것이 아니라 암호화된 숫자 데이터(Vector)로 변환하여 저장하여, 해킹되더라도 실제 얼굴 이미지를 복원할 수 없도록 함

> "사용자가 단순히 신발끈을 묶으려고 숙인 것을 '넘어짐'으로 오인해서 보호자에게 알람을 보내면 어떡하죠?"
> 
- **방어 전략:** * **복합 센서 퓨전:** 가속도 센서(기울기)뿐만 아니라 카메라 비전(지면과의 각도), 그리고 음성(사용자의 "괜찮아" 확인 절차)을 결합한 3단계 검증 시스템을 통해 오보율을 낮추기

### 하드웨어의 '외형적 거부감' (Stigma)

- **문제점:** 시각장애인들은 자신이 '장애인용 기기'를 착용하고 있다는 사실이 너무 눈에 띄는 것을 원치 않는 경우가 많습니다. 안경 위에 360도 카메라와 각종 센서가 주렁주렁 달리면 타인의 시선이 집중되는 부담(Stigma)이 생깁니다.
- **해결 방안:** 카메라와 센서를 안경테 안으로 최대한 매립하는 **'스텔스 디자인'**을 추구하거나, 오히려 최신 유행하는 '스마트 글래스'처럼 세련된 외형을 강조해야 합니다.

### 조도(빛) 및 날씨의 영향

- **문제점:** 카메라 기반 AI는 **밤(야간), 역광, 비 오는 날**에 성능이 급격히 떨어집니다. 가로등 없는 골목에서 "앞에 전봇대"를 인식하지 못하면 치명적인 사고로 이어질 수 있습니다.
- **해결 방안:** 카메라에만 의존하지 않고 **초음파(Ultrasonic)나 LiDAR 센서**를 혼합(Sensor Fusion)해야 합니다. 센서는 빛이 전혀 없어도 물체와의 거리를 정확히 잴 수 있기 때문입니다.

### 음성 안내의 '시차'와 '정보 과부하'

- **문제점:** AI가 상황을 분석하고 문장으로 만들어 TTS로 내뱉는 데는 보통 1~2초가 걸립니다. 하지만 걷는 도중에는 1초만 늦어도 이미 장애물에 부딪힌 뒤일 수 있습니다.
- **해결 방안:** * **즉각적인 비프음(Beep):** 위험할 땐 문장 대신 즉각적인 소리(삐!)로 먼저 경고합니다.
    - **짧은 키워드:** "전방에 의자가 있습니다" 대신 "앞, 의자"처럼 정보를 압축해서 전달합니다.

### 통신 의존도 (Edge vs Cloud)

- **문제점:** 복잡한 상황 판단을 위해 서버(클라우드)에 데이터를 보낼 경우, 지하철이나 엘리베이터처럼 **인터넷이 끊기는 곳**에서는 기기가 '먹통'이 됩니다.
- **해결 방안:** 핵심적인 안전 기능(장애물 인식, 넘어짐 감지)은 인터넷 없이도 작동하는 **'On-Device AI'**로 구현하고, 복잡한 질문 대답만 클라우드를 사용하도록 이원화해야 합니다.