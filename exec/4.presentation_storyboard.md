## SARVIS 발표 콘티 (15분)

---

**저번 중간발표때 적용한 코치님 말씀대로,
각 슬라이드는 적절히 쪼개서 발표자의 멘트에 해당하는 내용만 노출시키도록 제작하겠습니다!**

도입 4분

시연 6분 50초

구현 주안점 및 기술, 사용 모델 설명 3분

향후 발전 가능성 1분

### 1. 도입: 개요 및 목적, 프로젝트의 당위성 ( 4분 )

- **슬라이드 1: 표지 및 팀 소개**
  - "SARVIS"
  - **"얼굴과 목소리로 사용자를 찾아가는 지능형 모니터암"**

- **슬라이드 2: 프로젝트 배경 (Necessity)**
  - 데스크테리어 및 스마트 오피스 시장의 성장
  - 기존 모니터암의 한계: "수동 조작의 불편함", "고정된 시야각"
  - 멀티태스킹 환경에서의 "능동적인 디스플레이 위치 제어" 필요성

- **슬라이드 3: 페르소나 및 문제 정의**
  - **Persona**: 재택근무자, 요리 중 레시피를 보며 이동하는 사용자, 침대에 누워 영상을 편하게 보고 싶은 사용자
  - **Problem**: 자세를 바꿀 때마다 모니터를 일일이 손으로 옮겨야 함, 손에 뭐가 묻어 있을 때 조작 불가

- **슬라이드 4: 솔루션 제안 (SARVIS)**
  - **Smart Monitor Arm**: 사용자 위치를 추적하여 최적의 각도로 자동 조절
  - **Hands-free Control**: 음성 명령 및 제스처로 모니터 제어
  - **Extensibility**: 스마트폰, 태블릿, 포터블 모니터 등 다양한 디바이스 거치 가능

- **슬라이드 5: 핵심 기능 1 (Face Tracking)**
  - 카메라를 통해 사용자 안면 인식 및 위치 추적
  - 사용자가 이동하더라도 항상 정면을 바라보도록 모니터 각도 자동 조절 
  - InsightFace & OpenCV 기반의 부드러운 모터 제어

- **슬라이드 6: 핵심 기능 2 (Voice Command)**
  - 마이크 내장을 통한 "SARVIS" 호출어 인식
  - "오른쪽으로", "위로", "유튜브 틀어줘" 등 음성 명령 수행
  - 안드로이드 앱 연동을 통한 스마트 기기 제어 허브 역할

### 2. 시연 1: 인식 및 추적 ( 2분 30초 )

- **진행 순서:**
  - 회원가입 (60초)
  - 안면 스캔 기반 로그인 (30초)
  - 따라와, 이리와, 저리가 시연 (60초)

### 3. 시연 2: 프리셋 ( 1분 30초 )

- **진행 순서:**
  - 앱 내 방향키를 활용한 미세 위치 조정 (30초)
  - 자주 쓰는 위치(침대 모드, 데스크 모드 등) 프리셋 저장 및 불러오기 (30초)
  - 저장한 프리셋대로 모니터암이 정확히 이동하는지 시연 (30초)

### 4. 시연 3: 음성 명령 ( 1분 )

- **진행 순서:**
  - 백그라운드에서 앱이 작동하고 있음을 나타내는 상단바 노출 ( 10초 )
  - “SARVIS” 호출 시 반응(LED 등) 확인, “오른쪽으로”, “위로”, “멈춰” 음성 명령 시연 (50초)
  
### 5. 시연 4: 백그라운드에서 타앱(유튜브) 제어 ( 1분 20초 )

- **진행 순서:**
  - 거치된 디바이스(스마트폰/태블릿)에서 유튜브 재생
  - 설거지/요리 중인 상황 가정 -> 음성으로 "일시정지", "다음 영상" 제어 (60초)
  - 로그아웃 후 시연 종료 (20초)

### 6. 구현 주안점 및 기술, 사용 모델 설명 ( 3분 )

- **슬라이드 7: Tech Stack - Control & Brain**
  - **Frontend (Controller)**: React Native (Expo) - 모니터암 제어 인터페이스 제공
  - **Backend (Brain)**: Django & Channels - 사용자 명령 해석 및 로봇 팔 제어 신호 중계
  - **Communication**: WebSocket을 통한 초저지연 양방향 통신 실현

- **슬라이드 8: Tech Stack - Edge AI (Jetson)**
  - **Vision**: 사용자 얼굴 위치(XYZ 좌표) 실시간 추정 -> 로봇 팔 관절 각도(Inverse Kinematics) 계산
  - **Voice**: 온디바이스 음성 인식으로 네트워크 지연 없는 즉각적 반응
  - **Optimization**: TensorRT 가속을 통한 엣지 디바이스 성능 극대화

- **슬라이드 9: Hardware Mechanism**
  - **6-DOF Robot Arm**: 자유로운 관절 움직임으로 다양한 각도 구현
  - **Stability**: 모니터 무게를 지탱하면서도 부드럽게 움직이는 모터 제어 알고리즘 (PID 제어)
  - **Safety**: 충돌 감지 및 안전 범위 제한 로직 적용

### 7. 향후 발전 가능성 ( 디벨롭 ) ( 1분 )

- **슬라이드 11: Future Works**
  - **Gesture Control**: 손동작으로 화면 넘기기, 볼륨 조절 등 제스처 인식 강화
  - **Docking Station**: 모니터암 베이스에 무선 충전, USB 허브 기능 통합