# 제영호-싸비스(반응형 모니터암)

## 1. 프로젝트 개요

본 프로젝트는 **로봇팔(Robotic Arm) + 디스플레이 + 경량 AI**를 결합한 **사용자 추적형 스마트 모니터**를 개발하는 것을 목표로 한다.

---

## 2. 문제 정의

### 기존 모니터 사용의 불편

- 사용자가 이동하면 시야에서 벗어남
- 화상회의/공부 중 자세 변화에 취약
- 멀티태스킹 환경에서 몰입도 저하

---

## 3. 프로젝트 방향성

### ✅ 하는 것

- 사람 존재 및 위치 인식
- 화면 중심 유지 보조

### ❌ 하지 않는 것

- 얼굴 인식 / 사용자 식별
- 영상 저장 및 클라우드 전송

---

## 4. 시스템 아키텍처

### 전체 구조

```
[카메라]
   ↓
[경량 사용자 인식 AI]
   ↓
[위치/방향 추정 로직]
   ↓
[상태 판단 & 정책 엔진]
   ↓
[로봇팔 제어 모듈]
   ↓
[모터 구동]
```

---

## 5. 기술 스택 상세

### 5.1 AI / 비전 스택

**목적:** 사용자 존재 및 위치 인식 (식별 아님)

- Face / Upper-body Detection (경량 모델)
- Head Pose Estimation (Yaw / Pitch 중심)
- On-device inference only

**특징**

- 프레임 단위 처리 후 즉시 폐기
- 저장/전송 데이터 없음

---

### 5.2 임베디드 & 제어 스택

**핵심 역할:** 안정적이고 예측 가능한 움직임

- MCU + RTOS 기반 제어
- 상태 머신(State Machine)
- 히스테리시스 기반 반응 제어
- PID 기반 모터 제어

**중요 포인트**

- AI 출력은 "트리거" 역할만 수행
- 실제 움직임은 전통 제어 알고리즘 담당

---

### 5.3 기구 / 하드웨어 스택

- 2~3 DoF 저소음 로봇팔
- 진동 최소화 기구 설계
- 디스플레이 무게 중심 고려
- 물리적 카메라 셔터
- 하드웨어 LED 인디케이터

---

## 6. 프라이버시 원칙

### 원칙 1. On-device AI

- 영상 데이터 외부 전송 없음
- 메모리 상 즉시 처리/폐기

### 원칙 2. Non-identification

- 사람 인식 ≠ 사람 식별
- 개인 ID, 얼굴 DB 미사용

### 원칙 3. 물리적 신뢰 장치

- 카메라 셔터
- 물리 LED
- 전원 차단 시 카메라 OFF 보장

### 원칙 4. 사용자 통제

- AI 추적 ON/OFF
- 고정 모드 제공

---

## 7. UX

### 설계 목표

- "왜 움직였는지" 사용자가 이해 가능해야 함
- 필요할 때만 움직이고, 대부분은 정지

### 주요 UX 룰

- 미세 움직임 무시
- 일정 시간 이상 위치 변화 시만 반응
- 다중 사용자 시 화면 주시자 우선